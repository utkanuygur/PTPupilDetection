{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#@title Preperation\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!rm -rf sample_data\n",
        "!cp drive/MyDrive/Finals.zip .\n",
        "!unzip Finals.zip\n",
        "!mv Finals/data .\n",
        "!rm Finals.zip\n",
        "drive.flush_and_unmount()"
      ],
      "metadata": {
        "id": "QNAkZYa3YiOy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Required Libraries and Import Libraries\n",
        "!pip install torch torchvision matplotlib tqdm\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision.transforms import functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm.notebook import tqdm\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torchvision.datasets import CocoDetection\n",
        "import gc\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.detection import maskrcnn_resnet50_fpn, MaskRCNN_ResNet50_FPN_Weights\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "import imageio\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MRawP0piYPxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate Masks\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "def create_binary_masks(input_folder):\n",
        "    image_folder = os.path.join(input_folder, 'images')\n",
        "    label_folder = os.path.join(input_folder, 'labels')\n",
        "    mask_folder = os.path.join(input_folder, 'masks')\n",
        "    image_shape = (380, 540)\n",
        "\n",
        "    os.makedirs(mask_folder, exist_ok=True)\n",
        "\n",
        "    def create_binary_mask(center_x, center_y, major_axis, minor_axis, angle, image_shape):\n",
        "        mask = np.zeros(image_shape, dtype=np.uint8)\n",
        "        center = (int(center_x), int(center_y))\n",
        "        axes = (int(major_axis / 2), int(minor_axis / 2))\n",
        "        cv2.ellipse(mask, center, axes, angle, 0, 360, 255, -1)\n",
        "        return mask\n",
        "\n",
        "    image_files = [f for f in os.listdir(image_folder) if f.endswith(('.png', '.jpg'))]\n",
        "\n",
        "    for image_file in image_files:\n",
        "        csv_file = os.path.join(label_folder, os.path.splitext(image_file)[0] + '.csv')\n",
        "\n",
        "        if os.path.exists(csv_file):\n",
        "            df = pd.read_csv(csv_file)\n",
        "            mask_image = np.zeros(image_shape, dtype=np.uint8)\n",
        "\n",
        "            for index, row in df.iterrows():\n",
        "                center_x = row['Center_X']\n",
        "                center_y = row['Center_Y']\n",
        "                major_axis = row['Major_Axis']\n",
        "                minor_axis = row['Minor_Axis']\n",
        "                angle = row['Angle']\n",
        "                mask = create_binary_mask(center_x, center_y, major_axis, minor_axis, angle, image_shape)\n",
        "                mask_image = cv2.add(mask_image, mask)\n",
        "\n",
        "            output_path = os.path.join(mask_folder, os.path.splitext(image_file)[0] + '.gif')\n",
        "            img = Image.fromarray(mask_image)\n",
        "            img.save(output_path)\n",
        "\n",
        "    print('Masks created successfully.')\n",
        "\n",
        "create_binary_masks('data/train')\n",
        "create_binary_masks('data/val')\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "146pHMPfcSbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Dataset and Data Loader\n",
        "\n",
        "IMAGE_HEIGHT = 380\n",
        "IMAGE_WIDTH = 540\n",
        "\n",
        "class PupilDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms=None):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"images\"))))\n",
        "        self.masks = list(sorted(os.listdir(os.path.join(root, \"masks\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.root, \"images\", self.imgs[idx])\n",
        "        mask_path = os.path.join(self.root, \"masks\", self.masks[idx])\n",
        "        img = Image.open(img_path).convert(\"L\")\n",
        "        mask = Image.open(mask_path)\n",
        "\n",
        "        img_np = np.array(img)\n",
        "        mask_np = np.array(mask)\n",
        "\n",
        "        if self.transforms is not None:\n",
        "            transformed = self.transforms(image=img_np, mask=mask_np)\n",
        "            img_np = transformed['image']\n",
        "            mask_np = transformed['mask']\n",
        "\n",
        "        img = img_np.squeeze().astype(np.float32) / 255.0\n",
        "        img = torch.from_numpy(img).unsqueeze(0)\n",
        "\n",
        "        mask = torch.as_tensor(mask_np, dtype=torch.uint8)\n",
        "\n",
        "        obj_ids = torch.unique(mask)[1:]\n",
        "        masks = mask == obj_ids[:, None, None]\n",
        "        num_objs = len(obj_ids)\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            pos = torch.where(masks[i])\n",
        "            xmin = torch.min(pos[1])\n",
        "            xmax = torch.max(pos[1])\n",
        "            ymin = torch.min(pos[0])\n",
        "            ymax = torch.max(pos[0])\n",
        "            if xmin < xmax and ymin < ymax:\n",
        "                boxes.append([xmin.item(), ymin.item(), xmax.item(), ymax.item()])\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "        masks = masks.type(torch.uint8)\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"masks\"] = masks\n",
        "        target[\"image_id\"] = torch.tensor([idx])\n",
        "        if len(boxes) > 0:\n",
        "            target[\"area\"] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        else:\n",
        "            target[\"area\"] = torch.zeros((0,), dtype=torch.float32)\n",
        "        target[\"iscrowd\"] = torch.zeros((len(boxes),), dtype=torch.int64)\n",
        "\n",
        "        if len(boxes) == 0:\n",
        "            target[\"boxes\"] = torch.zeros((0, 4), dtype=torch.float32)\n",
        "            target[\"labels\"] = torch.zeros((0,), dtype=torch.int64)\n",
        "            target[\"masks\"] = torch.zeros((0, img.shape[1], img.shape[2]), dtype=torch.uint8)\n",
        "            target[\"area\"] = torch.zeros((0,), dtype=torch.float32)\n",
        "            target[\"iscrowd\"] = torch.zeros((0,), dtype=torch.int64)\n",
        "\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "def get_transform():\n",
        "    return A.Compose(\n",
        "        [\n",
        "            A.Rotate(limit=15, p=0.5),\n",
        "            A.HorizontalFlip(p=0.25),\n",
        "            A.VerticalFlip(p=0.25),\n",
        "            A.RandomResizedCrop(height=IMAGE_HEIGHT, width=IMAGE_WIDTH, scale=(0.9, 1.0), ratio=(0.9, 1.1), p=0.2),\n",
        "            A.RandomBrightnessContrast(p=0.2),\n",
        "            A.RandomGamma(p=0.2),\n",
        "        ],\n",
        "        additional_targets={'mask': 'image'}\n",
        "    )\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "def get_dataloader(root, batch_size=15, shuffle=False, num_workers=4):\n",
        "    transforms = get_transform() if not shuffle else None\n",
        "    dataset = PupilDataset(root, transforms)\n",
        "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers, collate_fn=collate_fn)\n",
        "    return data_loader\n"
      ],
      "metadata": {
        "id": "SbIeajuSYRpC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train Model\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = torchvision.models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
        "    model.best_val_loss = float('inf')\n",
        "    return model\n",
        "\n",
        "num_classes = 2\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "best_model_path = 'best_model.pth'\n",
        "if os.path.exists(best_model_path):\n",
        "    print(\"Loading best model...\")\n",
        "    model = get_model_instance_segmentation(num_classes)\n",
        "    checkpoint = torch.load(best_model_path, map_location=device)\n",
        "    if 'model_state_dict' in checkpoint and 'best_val_loss' in checkpoint:\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model.best_val_loss = checkpoint['best_val_loss']\n",
        "        print(\"Best model loaded successfully.\")\n",
        "    else:\n",
        "        print(\"Checkpoint does not contain expected keys. Initializing new model...\")\n",
        "else:\n",
        "    print(\"No existing best model found. Initializing new model...\")\n",
        "    model = get_model_instance_segmentation(num_classes)\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "train_data_loader = get_dataloader('data/train')\n",
        "val_data_loader = get_dataloader('data/val', shuffle=False)\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.Adam(params, lr=0.000001, weight_decay=0.000001)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "num_epochs = 100\n",
        "patience = 10\n",
        "counter = 0\n",
        "model.train()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    train_loader = tqdm(train_data_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    for images, targets in train_loader:\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "        loss_dict = model(images, targets)\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        epoch_loss += losses.item()\n",
        "        train_loader.set_postfix(loss=losses.item())\n",
        "    lr_scheduler.step()\n",
        "    val_loss = 0\n",
        "    num_valid_batches = 0\n",
        "    with torch.no_grad():\n",
        "        val_loader = tqdm(val_data_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\")\n",
        "        for images, targets in val_loader:\n",
        "            images = list(image.to(device) for image in images)\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "            loss_dict = model(images, targets)\n",
        "            losses = sum(loss for loss in loss_dict.values())\n",
        "            val_loss += losses.item()\n",
        "            val_loader.set_postfix(loss=losses.item())\n",
        "            num_valid_batches += 1\n",
        "    avg_val_loss = val_loss / num_valid_batches if num_valid_batches > 0 else 0\n",
        "    print(f\"Epoch {epoch+1}, Training Loss: {epoch_loss / len(train_data_loader):.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    if avg_val_loss < model.best_val_loss:\n",
        "        model.best_val_loss = avg_val_loss\n",
        "        torch.save({\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'best_val_loss': model.best_val_loss,\n",
        "        }, best_model_path)\n",
        "        print(f\"Saved best model with validation loss: {model.best_val_loss:.4f}\")\n",
        "        counter = 0\n",
        "    else:\n",
        "        counter += 1\n",
        "        print(f\"Early Stopping counter: {counter} out of {patience}\")\n",
        "\n",
        "    if counter >= patience:\n",
        "        print(\"Early stopping\")\n",
        "        break\n",
        "\n",
        "print(\"Training completed.\")"
      ],
      "metadata": {
        "id": "M0vvTAzNYYUa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Visualization\n",
        "def visualize(image, masks):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
        "    for mask in masks:\n",
        "        plt.imshow(mask.cpu().numpy(), alpha=0.5)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "masks = prediction['masks'] > 0.5\n",
        "visualize(image, masks)\n"
      ],
      "metadata": {
        "id": "EwEpaHZ1YgFD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Clear GPU Ram\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.reset_peak_memory_stats()\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "tERxvCoNmVVX",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Get the Segmentation\n",
        "class PupilDataset(Dataset):\n",
        "    def __init__(self, image_dir, label_dir, transforms=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.label_dir = label_dir\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "        self.transform = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        image_path = os.path.join(self.image_dir, img_name)\n",
        "        label_path = os.path.join(self.label_dir, os.path.splitext(img_name)[0] + '.csv')\n",
        "\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        label_data = pd.read_csv(label_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label_data\n",
        "\n",
        "def get_transform():\n",
        "    return transforms.Compose([\n",
        "        transforms.Resize((256, 256)),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    weights = MaskRCNN_ResNet50_FPN_Weights.COCO_V1\n",
        "    model = maskrcnn_resnet50_fpn(weights=weights)\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 256\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
        "    return model\n",
        "\n",
        "def load_model(model_path, num_classes):\n",
        "    model = get_model_instance_segmentation(num_classes)\n",
        "    checkpoint = torch.load(model_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "def draw_red_eyeball(image, mask):\n",
        "    mask = mask.squeeze().cpu().numpy()\n",
        "    image_np = image.permute(1, 2, 0).cpu().numpy()\n",
        "    image_np = (image_np * 255).astype(np.uint8)  # Ensure image is in uint8\n",
        "    mask = cv2.resize(mask, (image_np.shape[1], image_np.shape[0]))\n",
        "    mask = (mask > 0.5).astype(np.uint8)\n",
        "\n",
        "    # Create a red overlay with alpha transparency\n",
        "    red_overlay = np.zeros_like(image_np, dtype=np.uint8)\n",
        "    red_overlay[:, :, 0] = 255  # Red channel\n",
        "    alpha = 0.5  # Transparency factor\n",
        "    overlayed_image = cv2.addWeighted(image_np, 1 - alpha, red_overlay, alpha, 0)\n",
        "\n",
        "    # Apply the mask to the overlay\n",
        "    overlayed_image[mask == 0] = image_np[mask == 0]\n",
        "\n",
        "    return overlayed_image\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    images = [item[0] for item in batch]\n",
        "    labels = [item[1] for item in batch]\n",
        "    return images, labels\n",
        "\n",
        "def visualize_images_to_gif(image_dir, label_dir, model_path, output_gif_path):\n",
        "    transform = get_transform()\n",
        "\n",
        "    dataset = PupilDataset(image_dir, label_dir, transforms=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=custom_collate_fn)\n",
        "\n",
        "    model = load_model(model_path, num_classes=2)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    frames = []\n",
        "\n",
        "    for i, (image, label_data) in enumerate(dataloader):\n",
        "        image = image[0].to(device)  # Unpack single-element batch\n",
        "        with torch.no_grad():\n",
        "            prediction = model([image])\n",
        "\n",
        "        mask = prediction[0]['masks'][0, 0]\n",
        "        img_with_eyeball = draw_red_eyeball(image, mask)\n",
        "\n",
        "        img_with_eyeball = cv2.cvtColor(img_with_eyeball, cv2.COLOR_BGR2RGB)\n",
        "        frames.append(img_with_eyeball)\n",
        "\n",
        "    imageio.mimsave(output_gif_path, frames, fps=10)\n",
        "    print(f\"GIF saved to {output_gif_path}\")\n",
        "\n",
        "image_dir = 'data/train/images'\n",
        "label_dir = 'data/train/labels'\n",
        "model_path = 'best_model.pth'\n",
        "output_gif_path = 'output_video.gif'\n",
        "\n",
        "visualize_images_to_gif(image_dir, label_dir, model_path, output_gif_path)\n"
      ],
      "metadata": {
        "id": "jH1bROMVDPhc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}